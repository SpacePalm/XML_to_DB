{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import clickhouse_connect\n",
    "import os\n",
    "\n",
    "os.environ['NO_PROXY'] = '10.80.131.73'\n",
    "connection = clickhouse_connect.get_client(host = \"10.80.131.73\", port = 8123, username = 'test', password = 'secretPassword321!', database = 'test')\n",
    "\n",
    "document_info_index = 0\n",
    "document_info_date = ''\n",
    "\n",
    "vulnerability_db = {\"VulnerabilityID\":[],\"DocXMLDate\":[], \"Ordinal\":[], \"CVE\":[], \"Title\":[], \"CWE\":[], \"CWE_text\":[]}\n",
    "vulnerability_db_status = {\"VulnerabilityFK\":[], \"StatusType\": [], \"ProductID\":[]}\n",
    "vulnerability_db_notes = {\"VulnerabilityFK\":[], \"NotesTitle\":[], \"NotesType\":[], \"NotesOrdinal\":[], \"Note\":[]}\n",
    "vulnerability_db_threats = {\"VulnerabilityFK\":[], \"TreatsType\":[], \"Description\":[], \"ProductID\":[]}\n",
    "vulnerability_db_score_set = {\"VulnerabilityFK\":[],\"BaseScore\":[], \"TemporalScore\":[], \"Vector\":[], 'ProductID':[]}\n",
    "vulnerability_db_acknowledgment= {\"VulnerabilityFK\":[], \"Name\":[], \"URL\":[]}\n",
    "vulnerability_db_revision = {\"VulnerabilityFK\":[], \"Number\":[], 'Date':[], 'Description':[]}\n",
    "vulnerability_db_Remediations={\"VulnerabilityFK\":[], \"KB\":[], \"Type\":[], 'URL':[], \"ProductID\":[], 'SubType':[], 'FixedBuild':[]}\n",
    "\n",
    "productdb = {'ProductID':[], 'ProductName':[], 'productdbType':[], 'productdbName':[]}\n",
    "\n",
    "notes_db = {\"DocumentIDFK\":[], \"NoteID\": [], \"notes_dbTitle\":[], \"notes_dbAudience\":[], \"notes_dbType\":[], \"Ordinal\":[]}\n",
    "\n",
    "document_info_db = {\"DocumentID\":[], \"Alias\":[], 'Status':[], \"Version\":[], \"RevisionHistoryNumber\":[], \"RevisionHistoryDate\":[], \n",
    "                    \"RevisionHistoryDescription\":[], \"InitialReleaseDate\":[], \"CurrentReleaseDate\":[], 'Pubishertype':[], 'ContactDetails':[], 'IssuingAuthority':[], \n",
    "                    'DocumentTitle':[], 'DocumentType':[], 'vuln':[],'dc':[],'cvrf-common':[],'prod':[],'scap-core':[],'cvssv2':[],'cpe-lang':[],'sch':[],'cvrf':[]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ProductTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_tree(soup, productdb):\n",
    "    library = soup.find('ProductTree')\n",
    "\n",
    "    def process_node(node, productdb):\n",
    "\n",
    "        if node.name is not None:\n",
    "            if 'ProductID' in node.attrs:\n",
    "                productdb['ProductID'].append(node.attrs['ProductID'])\n",
    "                productdb['ProductName'].append(node.text)\n",
    "            \n",
    "            if 'Type' not in node.attrs and node.name != 'ProductTree':\n",
    "                if 'Type' in node.parent.attrs:\n",
    "                    productdb['productdbType'].append(node.parent.attrs['Type'])\n",
    "                    productdb['productdbName'].append(node.parent.attrs['Name'])\n",
    "                else:\n",
    "                    productdb['productdbType'].append(None)\n",
    "                    productdb['productdbName'].append(None)\n",
    "\n",
    "            for child in node.children:\n",
    "                process_node(child, productdb)\n",
    "\n",
    "\n",
    "    process_node(library, productdb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_Vulnerability(soup, vulnerability_db, vulnerability_db_status, vulnerability_db_notes, vulnerability_db_threats, vulnerability_db_score_set,vulnerability_db_acknowledgment, vulnerability_db_revision):\n",
    "    def process_vulnerability(node, vulnerability_db, vulnerability_index):\n",
    "        vulnerability_db['Ordinal'].append(node.get('Ordinal'))\n",
    "        vulnerability_db['Title'].append(node.find('Title').text if node.find('Title').text else None)\n",
    "        vulnerability_db['CVE'].append(node.find('CVE').text)\n",
    "        vulnerability_db['VulnerabilityID'].append(vulnerability_index+1)\n",
    "        vulnerability_db['DocXMLDate'].append(document_info_date)\n",
    "        vulnerability_db['CWE_text'].append(node.find('CWE').text if node.find('CWE') else '')\n",
    "        vulnerability_db['CWE'].append( node.find('CWE').get('ID') if node.find('CWE') else '')\n",
    "            \n",
    "\n",
    "    def process_status(node, vulnerability_db_status, vulnerability_index):\n",
    "        vulnerability_db_status['ProductID'].append(node.text)\n",
    "        vulnerability_db_status['StatusType'].append(node.parent.get('Type'))\n",
    "        vulnerability_db_status['VulnerabilityFK'].append(vulnerability_index)\n",
    "\n",
    "    def process_notes(node, vulnerability_db_notes, vulnerability_index):\n",
    "        vulnerability_db_notes['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_notes['NotesTitle'].append(node.get('Title'))\n",
    "        vulnerability_db_notes['NotesType'].append(node.get('Type'))\n",
    "        vulnerability_db_notes['NotesOrdinal'].append(node.get('Ordinal'))\n",
    "        vulnerability_db_notes['Note'].append(node.text)\n",
    "\n",
    "    def process_threats(node, vulnerability_db_threats, vulnerability_index):\n",
    "        vulnerability_db_threats['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_threats['TreatsType'].append(node.get('Type'))\n",
    "        product_id = node.find('ProductID')\n",
    "        vulnerability_db_threats['ProductID'].append(product_id.text if product_id else None)\n",
    "        description = node.find('Description')\n",
    "        vulnerability_db_threats['Description'].append(description.text if description else None)\n",
    "\n",
    "    def process_score_set(node, vulnerability_db_score_set, vulnerability_index):\n",
    "        vulnerability_db_score_set['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_score_set['BaseScore'].append(node.find('BaseScore').text)\n",
    "        vulnerability_db_score_set['TemporalScore'].append(node.find('TemporalScore').text)\n",
    "        vulnerability_db_score_set['Vector'].append(node.find('Vector').text)\n",
    "        vulnerability_db_score_set['ProductID'].append(node.find('ProductID').text)\n",
    "\n",
    "    def process_acknowledgment(node, vulnerability_db_acknowledgment, vulnerability_index):\n",
    "        vulnerability_db_acknowledgment['VulnerabilityFK'].append(vulnerability_index)\n",
    "        name = node.find('Name')\n",
    "        vulnerability_db_acknowledgment['Name'].append(name.text if name and name.text else None)\n",
    "        url = node.find('URL')\n",
    "        vulnerability_db_acknowledgment['URL'].append(url.text if url and url.text else None)\n",
    "\n",
    "    def process_revision(node, vulnerability_db_revision, vulnerability_index):\n",
    "        vulnerability_db_revision['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_revision['Number'].append(node.find('Number').text)\n",
    "        vulnerability_db_revision['Date'].append(node.find('Date').text)\n",
    "        vulnerability_db_revision['Description'].append(node.find('Description').text if node.find('Description').text else None)\n",
    "\n",
    "    def process_Remediations(node, vulnerability_db_Remediations, vulnerability_index):\n",
    "        vulnerability_db_Remediations['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_Remediations['KB'].append(node.find('Description').text)\n",
    "        vulnerability_db_Remediations['Type'].append(node.get('Type'))\n",
    "        vulnerability_db_Remediations['URL'].append(node.find('URL').text if node.find('URL') else '')\n",
    "        vulnerability_db_Remediations['ProductID'].append([tag.text for tag in node.find_all('ProductID')])\n",
    "        vulnerability_db_Remediations['SubType'].append(node.find('SubType').text if node.find('SubType') else '')\n",
    "        vulnerability_db_Remediations['FixedBuild'].append(node.find('FixedBuild').text if node.find('FixedBuild') else '')\n",
    "\n",
    "        for child in node.children:\n",
    "            vulnerability_db\n",
    "\n",
    "\n",
    "    def vulnerability(node, vulnerability_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        \n",
    "        vulnerability_index = len(vulnerability_db['Ordinal']) - 1\n",
    "        \n",
    "\n",
    "        if node.name == 'Vulnerability' and 'Ordinal' in node.attrs:\n",
    "            process_vulnerability(node, vulnerability_db, vulnerability_index)\n",
    "        elif node.name == 'ProductID' and node.parent.name == \"Status\":\n",
    "            process_status(node, vulnerability_db_status, vulnerability_index)\n",
    "        elif node.name == 'Note' and node.parent.name == \"Notes\":\n",
    "            process_notes(node, vulnerability_db_notes, vulnerability_index)\n",
    "        elif node.name == 'Threat' and node.parent.name == \"Threats\":\n",
    "            process_threats(node, vulnerability_db_threats, vulnerability_index)\n",
    "        elif node.name == 'ScoreSet' and node.parent.name == \"CVSSScoreSets\":\n",
    "            process_score_set(node, vulnerability_db_score_set, vulnerability_index)\n",
    "        elif node.name == 'Acknowledgment' and node.parent.name == 'Acknowledgments':\n",
    "            process_acknowledgment(node, vulnerability_db_acknowledgment, vulnerability_index)\n",
    "        elif node.name == 'Revision' and node.parent.name == 'RevisionHistory':\n",
    "            process_revision(node, vulnerability_db_revision, vulnerability_index)\n",
    "        elif node.name == 'Remediation' and node.parent.name == 'Remediations':\n",
    "            process_Remediations(node, vulnerability_db_Remediations, vulnerability_index)\n",
    "        \n",
    "\n",
    "        for child in node.children:\n",
    "            vulnerability(child, vulnerability_db)\n",
    "\n",
    "\n",
    "    lib = soup.find('cvrfdoc').children\n",
    "    for child in lib:\n",
    "        if child.name == \"Vulnerability\":\n",
    "            vulnerability(child, vulnerability_db)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DocumentNotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_DocumentNotes(soup, notes_db):\n",
    "    def document_notes(node, notes_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        notes_index = len(notes_db['notes_dbAudience'])\n",
    "        if node.name == 'Note' and node.parent.name == 'DocumentNotes':\n",
    "            notes_db[\"DocumentIDFK\"].append(document_info_index)\n",
    "            notes_db[\"notes_dbTitle\"].append(node.get('Title'))\n",
    "            notes_db[\"notes_dbAudience\"].append(node.get('Audience'))\n",
    "            notes_db[\"notes_dbType\"].append(node.get('Type'))\n",
    "            notes_db[\"Ordinal\"].append(node.get('Ordinal'))\n",
    "            notes_db[\"NoteID\"].append(notes_index)\n",
    "        \n",
    "        for child in node.children:\n",
    "            document_notes(child, notes_db) \n",
    "        \n",
    "\n",
    "    lib = soup.find('cvrfdoc').children\n",
    "    for child in lib:\n",
    "        if child.name == \"DocumentNotes\":\n",
    "            document_notes(child, notes_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DocumentTracking + DocumentPublisher + DocumentType + DocumentTitle + attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Doc_Info(soup, document_info_db):\n",
    "    def documen_tracking(node,document_info_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        \n",
    "        if node.name == \"ID\" and node.parent.name == \"Identification\":\n",
    "            document_info_db['DocumentID'].append(document_info_date)\n",
    "        elif node.name == \"Alias\" and node.parent.name == \"Identification\":\n",
    "            document_info_db[\"Alias\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Status\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"Status\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Version\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"Version\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Number\" and node.parent.name == \"Revision\":\n",
    "            document_info_db[\"RevisionHistoryNumber\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Date\" and node.parent.name == \"Revision\":\n",
    "            document_info_db[\"RevisionHistoryDate\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Description\" and node.parent.name == \"Revision\":\n",
    "            document_info_db[\"RevisionHistoryDescription\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"InitialReleaseDate\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"InitialReleaseDate\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"CurrentReleaseDate\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"CurrentReleaseDate\"].append(node.text if node.text else None)\n",
    "    \n",
    "    \n",
    "        for child in node.children:\n",
    "            documen_tracking(child, document_info_db) \n",
    "\n",
    "    def documen_publisher(node,document_info_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        \n",
    "        if node.name == 'DocumentPublisher' and node.parent.name == 'cvrfdoc':\n",
    "            document_info_db['Pubishertype'].append(node.get('Type'))\n",
    "        if node.name == 'ContactDetails' and node.parent.name == 'DocumentPublisher':\n",
    "            document_info_db['ContactDetails'].append(node.text if node.text else None)\n",
    "        if node.name == 'IssuingAuthority' and node.parent.name == 'DocumentPublisher':\n",
    "            document_info_db['IssuingAuthority'].append(node.text if node.text else None)\n",
    "\n",
    "        for child in node.children:\n",
    "            documen_publisher(child, document_info_db) \n",
    "\n",
    "    lib = soup.find('cvrfdoc')\n",
    "\n",
    "    document_info_db['vuln'].append(lib.get('xmlns:vuln'))\n",
    "    document_info_db['dc'].append(lib.get('xmlns:dc'))\n",
    "    document_info_db['cvrf-common'].append(lib.get('xmlns:cvrf-common'))\n",
    "    document_info_db['scap-core'].append(lib.get('xmlns:scap-core'))\n",
    "    document_info_db['prod'].append(lib.get('xmlns:prod'))\n",
    "    document_info_db['cvssv2'].append(lib.get('xmlns:cvssv2'))\n",
    "    document_info_db['cpe-lang'].append(lib.get('xmlns:cpe-lang'))\n",
    "    document_info_db['sch'].append(lib.get('xmlns:sch'))\n",
    "    document_info_db['cvrf'].append(lib.get('xmlns:cvrf'))\n",
    "\n",
    "    lib = soup.find('cvrfdoc').children\n",
    "    for child in lib:\n",
    "        if child.name == \"DocumentTracking\":\n",
    "            documen_tracking(child, document_info_db)\n",
    "        if child.name == \"DocumentPublisher\":\n",
    "            documen_publisher(child, document_info_db)\n",
    "        if child.name == 'DocumentTitle':\n",
    "            document_info_db['DocumentTitle'].append(child.text if child.text else None)\n",
    "        if child.name == 'DocumentType':\n",
    "            document_info_db['DocumentType'].append(child.text if child.text else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-May\n",
      "71 71 ['', '', 'CWE-591', '', 'CWE-591', '', 'CWE-125', 'CWE-476', 'CWE-126', 'CWE-908', 'CWE-125', 'CWE-126', 'CWE-415', 'CWE-122', 'CWE-284', 'CWE-843', 'CWE-190', 'CWE-591', 'CWE-416', 'CWE-122', 'CWE-190', 'CWE-20', 'CWE-416', 'CWE-918', 'CWE-94', 'CWE-73', 'CWE-20', 'CWE-416', 'CWE-285', '', 'CWE-122', 'CWE-59', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 'CWE-200', 'CWE-59', 'CWE-416', '', 'CWE-122', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "    VulnerabilityID DocXMLDate Ordinal             CVE  \\\n",
      "0                 0   2023-May      27  CVE-2023-24932   \n",
      "1                 1   2023-May      52  CVE-2023-28251   \n",
      "2                 2   2023-May      53  CVE-2023-28283   \n",
      "3                 3   2023-May      19  CVE-2023-24898   \n",
      "4                 4   2023-May      20  CVE-2023-24899   \n",
      "..              ...        ...     ...             ...   \n",
      "66               66   2023-May       0  CVE-2022-27404   \n",
      "67               67   2023-May       1  CVE-2022-27406   \n",
      "68               68   2023-May      67  CVE-2023-29932   \n",
      "69               69   2023-May       6  CVE-2023-20958   \n",
      "70               70   2023-May      68  CVE-2023-30570   \n",
      "\n",
      "                                                Title      CWE  \\\n",
      "0   Secure Boot Security Feature Bypass Vulnerability            \n",
      "1   Windows Driver Revocation List Security Featur...            \n",
      "2   Windows Lightweight Directory Access Protocol ...  CWE-591   \n",
      "3         Windows SMB Denial of Service Vulnerability            \n",
      "4   Windows Graphics Component Elevation of Privil...  CWE-591   \n",
      "..                                                ...      ...   \n",
      "66                                               None            \n",
      "67                                               None            \n",
      "68                                               None            \n",
      "69                                               None            \n",
      "70                                               None            \n",
      "\n",
      "                                             CWE_text  \n",
      "0                                                      \n",
      "1                                                      \n",
      "2   Sensitive Data Storage in Improperly Locked Me...  \n",
      "3                                                      \n",
      "4   Sensitive Data Storage in Improperly Locked Me...  \n",
      "..                                                ...  \n",
      "66                                                     \n",
      "67                                                     \n",
      "68                                                     \n",
      "69                                                     \n",
      "70                                                     \n",
      "\n",
      "[71 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# doc_month_array = [\"Aug\",\"Sep\",'Oct', \"Nov\", \"Dec\", \"Jan\", 'Feb', \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\"]\n",
    "# doc_year_array = ['2023', '2024']\n",
    "\n",
    "for i in ['2023']:\n",
    "    for j in ['May']:\n",
    "        soup = \"\"\n",
    "        url = f'https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/{i}-{j}'\n",
    "\n",
    "        # Получаем данные по ссылке\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Проверка успешности запроса\n",
    "        if response.status_code == 200:\n",
    "            print(f\"{i}-{j}\")\n",
    "            document_info_date = f\"{i}-{j}\"\n",
    "            document_info_index +=1\n",
    "            soup = BeautifulSoup(response.content, \"xml\")\n",
    "            product_tree(soup, productdb)\n",
    "            Get_Vulnerability(soup, vulnerability_db, vulnerability_db_status, vulnerability_db_notes, vulnerability_db_threats, vulnerability_db_score_set,vulnerability_db_acknowledgment, vulnerability_db_revision)\n",
    "            Get_DocumentNotes(soup, notes_db)\n",
    "            Doc_Info(soup, document_info_db)\n",
    "\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print(\"Не удалось получить данные, статус код:\", response.status_code)\n",
    "    \n",
    "\n",
    "print(len(vulnerability_db['CWE_text']), len(vulnerability_db['VulnerabilityID']), vulnerability_db['CWE'])\n",
    "\n",
    "productdb = pd.DataFrame(productdb)\n",
    "vulnerability_db = pd.DataFrame(vulnerability_db)\n",
    "vulnerability_db_status = pd.DataFrame(vulnerability_db_status)\n",
    "vulnerability_db_notes = pd.DataFrame(vulnerability_db_notes)\n",
    "vulnerability_db_threats = pd.DataFrame(vulnerability_db_threats)\n",
    "vulnerability_db_score_set = pd.DataFrame(vulnerability_db_score_set)\n",
    "vulnerability_db_acknowledgment = pd.DataFrame(vulnerability_db_acknowledgment)\n",
    "vulnerability_db_revision = pd.DataFrame(vulnerability_db_revision)\n",
    "vulnerability_db_Remediations = pd.DataFrame(vulnerability_db_Remediations)\n",
    "\n",
    "\n",
    "notes_db = pd.DataFrame(notes_db)\n",
    "document_info_db = pd.DataFrame(document_info_db)\n",
    "\n",
    "cve_table = vulnerability_db['CWE'].unique()\n",
    "print(vulnerability_db)\n",
    "vulnerability_db_Remediations.to_excel(\"result.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Match KB & CVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kb_lake = pd.read_csv('Security Updates 2024-10-08-021008pm.csv')\n",
    "\n",
    "# kb_lake = kb_lake[kb_lake['Article'].apply(lambda x: isinstance(x, int)) | kb_lake['Article'].astype(str).str.isnumeric()]\n",
    "# kb_lake['Release date'] = pd.to_datetime(kb_lake['Release date'], errors = 'coerce')\n",
    "# # kb_lake['Release date'] = kb_lake['Release date'].dt.date\n",
    "# kb_lake['Article'] = 'KB'+ kb_lake['Article']\n",
    "# kb_lake.rename(columns={\"Details\": 'CVE'}, inplace=True)\n",
    "\n",
    "\n",
    "# kb_lake = pd.merge(kb_lake, vulnerability_db, on='CVE', how='outer')\n",
    "# kb_lake.drop_duplicates(subset = ['Release date', 'Article', 'Build Number', 'CVE', 'DocXMLDate'], keep = False, inplace=True)\n",
    "\n",
    "\n",
    "# kb_lake = kb_lake[~kb_lake['CVE'].str.startswith('ADV')]\n",
    "# kb_lake = kb_lake.reset_index()\n",
    "# kb_lake.drop(columns=['Ordinal', 'Title', 'VulnerabilityID','Product', 'Platform', 'Article (Link)', 'Download', 'Download (Link)', 'Impact', 'Max Severity', 'Details (Link)', 'index'], inplace=True)\n",
    "# kb_lake['id'] = range(0, len(kb_lake))\n",
    "\n",
    "# print(productdb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DF to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulnerability_db.drop(columns=['Ordinal'], inplace = True)\n",
    "vulnerability_db_notes.drop(columns=['NotesOrdinal'], inplace = True)\n",
    "productdb.drop(columns=['productdbName'], inplace = True)\n",
    "document_info_db.drop(columns=['Alias'], inplace = True)\n",
    "\n",
    "vulnerability_db_revision['Date'] = pd.to_datetime(vulnerability_db_revision['Date'])\n",
    "document_info_db['RevisionHistoryDate'] = pd.to_datetime(document_info_db['RevisionHistoryDate'])\n",
    "document_info_db['InitialReleaseDate'] = pd.to_datetime(document_info_db['InitialReleaseDate'])\n",
    "document_info_db['CurrentReleaseDate'] = pd.to_datetime(document_info_db['CurrentReleaseDate'])\n",
    "\n",
    "vulnerability_db_status['id'] = range(0, len(vulnerability_db_status))\n",
    "vulnerability_db_notes['id'] = range(0, len(vulnerability_db_notes))\n",
    "vulnerability_db_threats['id'] = range(0, len(vulnerability_db_threats))\n",
    "vulnerability_db_score_set['id'] = range(0, len(vulnerability_db_score_set))\n",
    "vulnerability_db_revision['id'] = range(0, len(vulnerability_db_revision))\n",
    "vulnerability_db_Remediations['id'] = range(0, len(vulnerability_db_Remediations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VulnerabilityFK     int64\n",
      "KB                 object\n",
      "Type               object\n",
      "URL                object\n",
      "ProductID          object\n",
      "SubType            object\n",
      "FixedBuild         object\n",
      "id                  int64\n",
      "dtype: object\n",
      "    VulnerabilityFK Number                Date  \\\n",
      "0                 0    2.2 2023-07-18 07:00:00   \n",
      "1                 0    4.0 2024-07-09 07:00:00   \n",
      "2                 0    1.0 2023-05-09 07:00:00   \n",
      "3                 0    2.0 2023-07-11 07:00:00   \n",
      "4                 0    2.1 2023-07-14 07:00:00   \n",
      "..              ...    ...                 ...   \n",
      "93               67    2.0 2022-05-11 00:00:00   \n",
      "94               67    3.0 2023-05-23 00:00:00   \n",
      "95               68    1.0 2023-05-09 00:00:00   \n",
      "96               69    1.0 2023-05-23 00:00:00   \n",
      "97               70    1.0 2023-05-29 00:00:00   \n",
      "\n",
      "                                          Description  id  \n",
      "0   <p>Removed the Security Hotpatch Update for th...   0  \n",
      "1   <p>Updated the Security Updates table to inclu...   1  \n",
      "2                     <p>Information published.</p>\\n   2  \n",
      "3   <p>In the Security Updates table, added all su...   3  \n",
      "4   <p>CORRECTED REVISION: To comprehensively addr...   4  \n",
      "..                                                ...  ..  \n",
      "93         <p>Added freetype to CBL-Mariner 1.0</p>\\n  93  \n",
      "94       <p>Added qt5-qtbase to CBL-Mariner 2.0</p>\\n  94  \n",
      "95                    <p>Information published.</p>\\n  95  \n",
      "96                    <p>Information published.</p>\\n  96  \n",
      "97                    <p>Information published.</p>\\n  97  \n",
      "\n",
      "[98 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# kb_lake.rename(columns={\"Release date\": 'release_date', \"Article\": 'kb',\"Build Number\": 'build_number',\"CVE\": 'cve',\"DocXMLDate\": 'doc_xml_date'}, inplace=True)\n",
    "# kb_lake['release_date'] = kb_lake['release_date'].astype(str)\n",
    "# kb_lake.fillna('', inplace = True)\n",
    "print(vulnerability_db_Remediations.dtypes)\n",
    "\n",
    "# connection.insert_df('kb', kb_lake, column_names = [\"release_date\", 'kb', 'build_number', 'cve', 'doc_xml_date', 'id'])\n",
    "connection.insert_df('vulnerability', vulnerability_db, column_names = [\"id\", 'doc_xml_date', 'cve', 'title', 'cwe', 'cwe_text'])\n",
    "connection.insert_df('vulnerability_status', vulnerability_db_status, column_names = [\"vulnerability_fk\", 'status_type', 'product_id', 'id'])\n",
    "connection.insert_df('vulnerability_notes', vulnerability_db_notes, column_names = [\"vulnerability_fk\", 'title', 'notes_type', 'note', 'id'])\n",
    "connection.insert_df('vulnerability_threats', vulnerability_db_threats, column_names = [\"vulnerability_fk\", 'threats_type', 'description', 'product_id', 'id'])\n",
    "connection.insert_df('vulnerability_score_set', vulnerability_db_score_set, column_names = [\"vulnerability_fk\", 'base_score', 'temporal_score', 'vector', 'product_id', 'id'])\n",
    "connection.insert_df('vulnerability_revision', vulnerability_db_revision, column_names = [\"vulnerability_fk\", 'number', 'revision_date', 'description', 'id'])\n",
    "connection.insert_df('vulnerability_remediation', vulnerability_db_Remediations, column_names = [\"vulnerability_fk\", 'kb', 'remediation_type', 'url','prodict_id','subtype', 'fixed_build', 'id'])\n",
    "connection.insert_df('product', productdb, column_names = ['id', \"product_name\", 'product_type'])\n",
    "connection.insert_df('document_info', document_info_db, column_names = [\"id\", 'status', 'version', 'revision_history_number', 'revision_history_date', 'revision_history_description'\n",
    "                                                                        , 'initial_relise_date', 'current_relise_date', 'publisher_type', 'contact_details'\n",
    "                                                                        , 'issuring_authority', 'document_title', 'document_type', 'vlun'\n",
    "                                                                        , 'dc', 'cvrf_common', 'prod', 'scap_core', 'cvssv2', 'cpe_lang', 'sch', 'cvrf'])\n",
    "\n",
    "\n",
    "print(vulnerability_db_revision)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
