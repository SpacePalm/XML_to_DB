{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import clickhouse_connect\n",
    "import os\n",
    "\n",
    "os.environ['NO_PROXY'] = '10.80.131.73'\n",
    "connection = clickhouse_connect.get_client(host = \"10.80.131.73\", port = 8123, username = 'test', password = 'secretPassword321!', database = 'test')\n",
    "\n",
    "document_info_index = 0\n",
    "document_info_date = ''\n",
    "\n",
    "vulnerability_db = {\"VulnerabilityID\":[],\"DocXMLDate\":[], \"Ordinal\":[], \"CVE\":[], \"Title\":[], \"CWE\":[], \"CWE_text\":[]}\n",
    "vulnerability_db_status = {\"VulnerabilityFK\":[], \"StatusType\": [], \"ProductID\":[]}\n",
    "vulnerability_db_notes = {\"VulnerabilityFK\":[], \"NotesTitle\":[], \"NotesType\":[], \"NotesOrdinal\":[], \"Note\":[]}\n",
    "vulnerability_db_threats = {\"VulnerabilityFK\":[], \"TreatsType\":[], \"Description\":[], \"ProductID\":[]}\n",
    "vulnerability_db_score_set = {\"VulnerabilityFK\":[],\"BaseScore\":[], \"TemporalScore\":[], \"Vector\":[], 'ProductID':[]}\n",
    "vulnerability_db_acknowledgment= {\"VulnerabilityFK\":[], \"Name\":[], \"URL\":[]}\n",
    "vulnerability_db_revision = {\"VulnerabilityFK\":[], \"Number\":[], 'Date':[], 'Description':[]}\n",
    "vulnerability_db_Remediations={\"VulnerabilityFK\":[], \"KB\":[], \"Type\":[], 'URL':[], \"ProductID\":[], 'SubType':[], 'FixedBuild':[]}\n",
    "\n",
    "productdb = {'ProductID':[], 'ProductName':[], 'productdbType':[], 'productdbName':[]}\n",
    "\n",
    "notes_db = {\"DocumentIDFK\":[], \"NoteID\": [], \"notes_dbTitle\":[], \"notes_dbAudience\":[], \"notes_dbType\":[], \"Ordinal\":[]}\n",
    "\n",
    "document_info_db = {\"DocumentID\":[], \"Alias\":[], 'Status':[], \"Version\":[], \"RevisionHistoryNumber\":[], \"RevisionHistoryDate\":[], \n",
    "                    \"RevisionHistoryDescription\":[], \"InitialReleaseDate\":[], \"CurrentReleaseDate\":[], 'Pubishertype':[], 'ContactDetails':[], 'IssuingAuthority':[], \n",
    "                    'DocumentTitle':[], 'DocumentType':[], 'vuln':[],'dc':[],'cvrf-common':[],'prod':[],'scap-core':[],'cvssv2':[],'cpe-lang':[],'sch':[],'cvrf':[]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ProductTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_tree(soup, productdb):\n",
    "    library = soup.find('ProductTree')\n",
    "\n",
    "    def process_node(node, productdb):\n",
    "\n",
    "        if node.name is not None:\n",
    "            if 'ProductID' in node.attrs:\n",
    "                productdb['ProductID'].append(node.attrs['ProductID'])\n",
    "                productdb['ProductName'].append(node.text)\n",
    "            \n",
    "            if 'Type' not in node.attrs and node.name != 'ProductTree':\n",
    "                if 'Type' in node.parent.attrs:\n",
    "                    productdb['productdbType'].append(node.parent.attrs['Type'])\n",
    "                    productdb['productdbName'].append(node.parent.attrs['Name'])\n",
    "                else:\n",
    "                    productdb['productdbType'].append(None)\n",
    "                    productdb['productdbName'].append(None)\n",
    "\n",
    "            for child in node.children:\n",
    "                process_node(child, productdb)\n",
    "\n",
    "\n",
    "    process_node(library, productdb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_Vulnerability(soup, vulnerability_db, vulnerability_db_status, vulnerability_db_notes, vulnerability_db_threats, vulnerability_db_score_set,vulnerability_db_acknowledgment, vulnerability_db_revision):\n",
    "    def process_vulnerability(node, vulnerability_db, vulnerability_index):\n",
    "        vulnerability_db['Ordinal'].append(node.get('Ordinal'))\n",
    "        vulnerability_db['Title'].append(node.find('Title').text if node.find('Title').text else None)\n",
    "        vulnerability_db['CVE'].append(node.find('CVE').text)\n",
    "        vulnerability_db['VulnerabilityID'].append(vulnerability_index+1)\n",
    "        vulnerability_db['DocXMLDate'].append(document_info_date)\n",
    "        vulnerability_db['CWE_text'].append(node.find('CWE').text if node.find('CWE') else '')\n",
    "        vulnerability_db['CWE'].append( node.find('CWE').get('ID') if node.find('CWE') else '')\n",
    "            \n",
    "\n",
    "    def process_status(node, vulnerability_db_status, vulnerability_index):\n",
    "        vulnerability_db_status['ProductID'].append(node.text)\n",
    "        vulnerability_db_status['StatusType'].append(node.parent.get('Type'))\n",
    "        vulnerability_db_status['VulnerabilityFK'].append(vulnerability_index)\n",
    "\n",
    "    def process_notes(node, vulnerability_db_notes, vulnerability_index):\n",
    "        vulnerability_db_notes['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_notes['NotesTitle'].append(node.get('Title'))\n",
    "        vulnerability_db_notes['NotesType'].append(node.get('Type'))\n",
    "        vulnerability_db_notes['NotesOrdinal'].append(node.get('Ordinal'))\n",
    "        vulnerability_db_notes['Note'].append(node.text)\n",
    "\n",
    "    def process_threats(node, vulnerability_db_threats, vulnerability_index):\n",
    "        vulnerability_db_threats['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_threats['TreatsType'].append(node.get('Type'))\n",
    "        product_id = node.find('ProductID')\n",
    "        vulnerability_db_threats['ProductID'].append(product_id.text if product_id else None)\n",
    "        description = node.find('Description')\n",
    "        vulnerability_db_threats['Description'].append(description.text if description else None)\n",
    "\n",
    "    def process_score_set(node, vulnerability_db_score_set, vulnerability_index):\n",
    "        vulnerability_db_score_set['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_score_set['BaseScore'].append(node.find('BaseScore').text)\n",
    "        vulnerability_db_score_set['TemporalScore'].append(node.find('TemporalScore').text)\n",
    "        vulnerability_db_score_set['Vector'].append(node.find('Vector').text)\n",
    "        vulnerability_db_score_set['ProductID'].append(node.find('ProductID').text)\n",
    "\n",
    "    def process_acknowledgment(node, vulnerability_db_acknowledgment, vulnerability_index):\n",
    "        vulnerability_db_acknowledgment['VulnerabilityFK'].append(vulnerability_index)\n",
    "        name = node.find('Name')\n",
    "        vulnerability_db_acknowledgment['Name'].append(name.text if name and name.text else None)\n",
    "        url = node.find('URL')\n",
    "        vulnerability_db_acknowledgment['URL'].append(url.text if url and url.text else None)\n",
    "\n",
    "    def process_revision(node, vulnerability_db_revision, vulnerability_index):\n",
    "        vulnerability_db_revision['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_revision['Number'].append(node.find('Number').text)\n",
    "        vulnerability_db_revision['Date'].append(node.find('Date').text)\n",
    "        vulnerability_db_revision['Description'].append(node.find('Description').text if node.find('Description').text else None)\n",
    "\n",
    "    def process_Remediations(node, vulnerability_db_Remediations, vulnerability_index):\n",
    "        vulnerability_db_Remediations['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_Remediations['KB'].append(node.find('Description').text)\n",
    "        vulnerability_db_Remediations['Type'].append(node.get('Type'))\n",
    "        vulnerability_db_Remediations['URL'].append(node.find('URL').text if node.find('URL') else '')\n",
    "        vulnerability_db_Remediations['ProductID'].append([tag.text for tag in node.find_all('ProductID')])\n",
    "        vulnerability_db_Remediations['SubType'].append(node.find('SubType').text if node.find('SubType') else '')\n",
    "        vulnerability_db_Remediations['FixedBuild'].append(node.find('FixedBuild').text if node.find('FixedBuild') else '')\n",
    "\n",
    "        for child in node.children:\n",
    "            vulnerability_db\n",
    "\n",
    "\n",
    "    def vulnerability(node, vulnerability_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        \n",
    "        vulnerability_index = len(vulnerability_db['Ordinal']) - 1\n",
    "        \n",
    "\n",
    "        if node.name == 'Vulnerability' and 'Ordinal' in node.attrs:\n",
    "            process_vulnerability(node, vulnerability_db, vulnerability_index)\n",
    "        elif node.name == 'ProductID' and node.parent.name == \"Status\":\n",
    "            process_status(node, vulnerability_db_status, vulnerability_index)\n",
    "        elif node.name == 'Note' and node.parent.name == \"Notes\":\n",
    "            process_notes(node, vulnerability_db_notes, vulnerability_index)\n",
    "        elif node.name == 'Threat' and node.parent.name == \"Threats\":\n",
    "            process_threats(node, vulnerability_db_threats, vulnerability_index)\n",
    "        elif node.name == 'ScoreSet' and node.parent.name == \"CVSSScoreSets\":\n",
    "            process_score_set(node, vulnerability_db_score_set, vulnerability_index)\n",
    "        elif node.name == 'Acknowledgment' and node.parent.name == 'Acknowledgments':\n",
    "            process_acknowledgment(node, vulnerability_db_acknowledgment, vulnerability_index)\n",
    "        elif node.name == 'Revision' and node.parent.name == 'RevisionHistory':\n",
    "            process_revision(node, vulnerability_db_revision, vulnerability_index)\n",
    "        elif node.name == 'Remediation' and node.parent.name == 'Remediations':\n",
    "            process_Remediations(node, vulnerability_db_Remediations, vulnerability_index)\n",
    "        \n",
    "\n",
    "        for child in node.children:\n",
    "            vulnerability(child, vulnerability_db)\n",
    "\n",
    "\n",
    "    lib = soup.find('cvrfdoc').children\n",
    "    for child in lib:\n",
    "        if child.name == \"Vulnerability\":\n",
    "            vulnerability(child, vulnerability_db)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DocumentNotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_DocumentNotes(soup, notes_db):\n",
    "    def document_notes(node, notes_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        notes_index = len(notes_db['notes_dbAudience'])\n",
    "        if node.name == 'Note' and node.parent.name == 'DocumentNotes':\n",
    "            notes_db[\"DocumentIDFK\"].append(document_info_index)\n",
    "            notes_db[\"notes_dbTitle\"].append(node.get('Title'))\n",
    "            notes_db[\"notes_dbAudience\"].append(node.get('Audience'))\n",
    "            notes_db[\"notes_dbType\"].append(node.get('Type'))\n",
    "            notes_db[\"Ordinal\"].append(node.get('Ordinal'))\n",
    "            notes_db[\"NoteID\"].append(notes_index)\n",
    "        \n",
    "        for child in node.children:\n",
    "            document_notes(child, notes_db) \n",
    "        \n",
    "\n",
    "    lib = soup.find('cvrfdoc').children\n",
    "    for child in lib:\n",
    "        if child.name == \"DocumentNotes\":\n",
    "            document_notes(child, notes_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DocumentTracking + DocumentPublisher + DocumentType + DocumentTitle + attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Doc_Info(soup, document_info_db):\n",
    "    def documen_tracking(node,document_info_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        \n",
    "        if node.name == \"ID\" and node.parent.name == \"Identification\":\n",
    "            document_info_db['DocumentID'].append(document_info_date)\n",
    "        elif node.name == \"Alias\" and node.parent.name == \"Identification\":\n",
    "            document_info_db[\"Alias\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Status\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"Status\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Version\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"Version\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Number\" and node.parent.name == \"Revision\":\n",
    "            document_info_db[\"RevisionHistoryNumber\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Date\" and node.parent.name == \"Revision\":\n",
    "            document_info_db[\"RevisionHistoryDate\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Description\" and node.parent.name == \"Revision\":\n",
    "            document_info_db[\"RevisionHistoryDescription\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"InitialReleaseDate\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"InitialReleaseDate\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"CurrentReleaseDate\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"CurrentReleaseDate\"].append(node.text if node.text else None)\n",
    "    \n",
    "    \n",
    "        for child in node.children:\n",
    "            documen_tracking(child, document_info_db) \n",
    "\n",
    "    def documen_publisher(node,document_info_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        \n",
    "        if node.name == 'DocumentPublisher' and node.parent.name == 'cvrfdoc':\n",
    "            document_info_db['Pubishertype'].append(node.get('Type'))\n",
    "        if node.name == 'ContactDetails' and node.parent.name == 'DocumentPublisher':\n",
    "            document_info_db['ContactDetails'].append(node.text if node.text else None)\n",
    "        if node.name == 'IssuingAuthority' and node.parent.name == 'DocumentPublisher':\n",
    "            document_info_db['IssuingAuthority'].append(node.text if node.text else None)\n",
    "\n",
    "        for child in node.children:\n",
    "            documen_publisher(child, document_info_db) \n",
    "\n",
    "    lib = soup.find('cvrfdoc')\n",
    "\n",
    "    document_info_db['vuln'].append(lib.get('xmlns:vuln'))\n",
    "    document_info_db['dc'].append(lib.get('xmlns:dc'))\n",
    "    document_info_db['cvrf-common'].append(lib.get('xmlns:cvrf-common'))\n",
    "    document_info_db['scap-core'].append(lib.get('xmlns:scap-core'))\n",
    "    document_info_db['prod'].append(lib.get('xmlns:prod'))\n",
    "    document_info_db['cvssv2'].append(lib.get('xmlns:cvssv2'))\n",
    "    document_info_db['cpe-lang'].append(lib.get('xmlns:cpe-lang'))\n",
    "    document_info_db['sch'].append(lib.get('xmlns:sch'))\n",
    "    document_info_db['cvrf'].append(lib.get('xmlns:cvrf'))\n",
    "\n",
    "    lib = soup.find('cvrfdoc').children\n",
    "    for child in lib:\n",
    "        if child.name == \"DocumentTracking\":\n",
    "            documen_tracking(child, document_info_db)\n",
    "        if child.name == \"DocumentPublisher\":\n",
    "            documen_publisher(child, document_info_db)\n",
    "        if child.name == 'DocumentTitle':\n",
    "            document_info_db['DocumentTitle'].append(child.text if child.text else None)\n",
    "        if child.name == 'DocumentType':\n",
    "            document_info_db['DocumentType'].append(child.text if child.text else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-Aug\n",
      "2023-Sep\n",
      "2023-Oct\n",
      "2023-Nov\n",
      "2023-Dec\n",
      "2023-Jan\n",
      "2023-Feb\n",
      "2023-Mar\n",
      "2023-Apr\n",
      "2023-May\n",
      "2023-Jun\n",
      "2023-Jul\n",
      "2024-Aug\n",
      "2024-Sep\n",
      "2024-Oct\n",
      "Не удалось получить данные, статус код: 404\n",
      "Не удалось получить данные, статус код: 404\n",
      "2024-Jan\n",
      "2024-Feb\n",
      "2024-Mar\n",
      "2024-Apr\n",
      "2024-May\n",
      "2024-Jun\n",
      "2024-Jul\n"
     ]
    }
   ],
   "source": [
    "doc_month_array = [\"Aug\",\"Sep\",'Oct', \"Nov\", \"Dec\", \"Jan\", 'Feb', \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\"]\n",
    "doc_year_array = ['2023', '2024']\n",
    "\n",
    "for i in doc_year_array:\n",
    "    for j in doc_month_array:\n",
    "        soup = \"\"\n",
    "        url = f'https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/{i}-{j}'\n",
    "\n",
    "        # Получаем данные по ссылке\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Проверка успешности запроса\n",
    "        if response.status_code == 200:\n",
    "            print(f\"{i}-{j}\")\n",
    "            document_info_date = f\"{i}-{j}\"\n",
    "            document_info_index +=1\n",
    "            soup = BeautifulSoup(response.content, \"xml\")\n",
    "            product_tree(soup, productdb)\n",
    "            Get_Vulnerability(soup, vulnerability_db, vulnerability_db_status, vulnerability_db_notes, vulnerability_db_threats, vulnerability_db_score_set,vulnerability_db_acknowledgment, vulnerability_db_revision)\n",
    "            Get_DocumentNotes(soup, notes_db)\n",
    "            Doc_Info(soup, document_info_db)\n",
    "\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print(\"Не удалось получить данные, статус код:\", response.status_code)\n",
    "    \n",
    "\n",
    "productdb = pd.DataFrame(productdb)\n",
    "vulnerability_db = pd.DataFrame(vulnerability_db)\n",
    "vulnerability_db_status = pd.DataFrame(vulnerability_db_status)\n",
    "vulnerability_db_notes = pd.DataFrame(vulnerability_db_notes)\n",
    "vulnerability_db_threats = pd.DataFrame(vulnerability_db_threats)\n",
    "vulnerability_db_score_set = pd.DataFrame(vulnerability_db_score_set)\n",
    "vulnerability_db_acknowledgment = pd.DataFrame(vulnerability_db_acknowledgment)\n",
    "vulnerability_db_revision = pd.DataFrame(vulnerability_db_revision)\n",
    "vulnerability_db_Remediations = pd.DataFrame(vulnerability_db_Remediations)\n",
    "\n",
    "\n",
    "notes_db = pd.DataFrame(notes_db)\n",
    "document_info_db = pd.DataFrame(document_info_db)\n",
    "\n",
    "cve_table = vulnerability_db['CWE'].unique()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Create tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CreateTable.sql', 'r') as f:\n",
    "    query = f.read()\n",
    "    f.close()\n",
    "query = query.split(';')\n",
    "for i in query:\n",
    "    connection.query(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DF to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vulnerability_db.drop(columns=['Ordinal'], inplace = True)\n",
    "vulnerability_db_notes.drop(columns=['NotesOrdinal'], inplace = True)\n",
    "productdb.drop(columns=['productdbName'], inplace = True)\n",
    "document_info_db.drop(columns=['Alias'], inplace = True)\n",
    "\n",
    "vulnerability_db_revision['Date'] = pd.to_datetime(vulnerability_db_revision['Date'])\n",
    "document_info_db['RevisionHistoryDate'] = pd.to_datetime(document_info_db['RevisionHistoryDate'])\n",
    "document_info_db['InitialReleaseDate'] = pd.to_datetime(document_info_db['InitialReleaseDate'])\n",
    "document_info_db['CurrentReleaseDate'] = pd.to_datetime(document_info_db['CurrentReleaseDate'])\n",
    "\n",
    "vulnerability_db_status['id'] = range(0, len(vulnerability_db_status))\n",
    "vulnerability_db_notes['id'] = range(0, len(vulnerability_db_notes))\n",
    "vulnerability_db_threats['id'] = range(0, len(vulnerability_db_threats))\n",
    "vulnerability_db_score_set['id'] = range(0, len(vulnerability_db_score_set))\n",
    "vulnerability_db_revision['id'] = range(0, len(vulnerability_db_revision))\n",
    "vulnerability_db_Remediations['id'] = range(0, len(vulnerability_db_Remediations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<clickhouse_connect.driver.summary.QuerySummary at 0x7f6ce46afca0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "connection.insert_df('vulnerability', vulnerability_db, column_names = [\"id\", 'doc_xml_date', 'cve', 'title', 'cwe', 'cwe_text'])\n",
    "connection.insert_df('vulnerability_status', vulnerability_db_status, column_names = [\"vulnerability_fk\", 'status_type', 'product_id', 'id'])\n",
    "connection.insert_df('vulnerability_notes', vulnerability_db_notes, column_names = [\"vulnerability_fk\", 'title', 'notes_type', 'note', 'id'])\n",
    "connection.insert_df('vulnerability_threats', vulnerability_db_threats, column_names = [\"vulnerability_fk\", 'threats_type', 'description', 'product_id', 'id'])\n",
    "connection.insert_df('vulnerability_score_set', vulnerability_db_score_set, column_names = [\"vulnerability_fk\", 'base_score', 'temporal_score', 'vector', 'product_id', 'id'])\n",
    "connection.insert_df('vulnerability_revision', vulnerability_db_revision, column_names = [\"vulnerability_fk\", 'number', 'revision_date', 'description', 'id'])\n",
    "connection.insert_df('vulnerability_remediation', vulnerability_db_Remediations, column_names = [\"vulnerability_fk\", 'kb', 'remediation_type', 'url','product_id','subtype', 'fixed_build', 'id'])\n",
    "connection.insert_df('product', productdb, column_names = ['id', \"product_name\", 'product_type'])\n",
    "connection.insert_df('document_info', document_info_db, column_names = [\"id\", 'status', 'version', 'revision_history_number', 'revision_history_date', 'revision_history_description'\n",
    "                                                                        , 'initial_relise_date', 'current_relise_date', 'publisher_type', 'contact_details'\n",
    "                                                                        , 'issuring_authority', 'document_title', 'document_type', 'vlun'\n",
    "                                                                        , 'dc', 'cvrf_common', 'prod', 'scap_core', 'cvssv2', 'cpe_lang', 'sch', 'cvrf'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Fill Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "DatabaseError",
     "evalue": ":HTTPDriver for http://10.80.131.73:8123 returned response code 400)\n Code: 62. DB::Exception: Syntax error: failed at position 1605 ('create') (line 57, col 1): create view cve_data as\n  SELECT DISTINCT\n    v.id as id,\n    v.doc_xml_date as doc_xml_date,\n    v.cve as cve,\n    v.title as vul_title,\n    v.cwe as cwe,\n    . Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 24.4.1.2088 (official build))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m query \u001b[38;5;241m=\u001b[39m query\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m query:\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_connect/driver/client.py:193\u001b[0m, in \u001b[0;36mClient.query\u001b[0;34m(self, query, parameters, settings, query_formats, column_formats, encoding, use_none, column_oriented, use_numpy, max_str_len, context, query_tz, column_tzs, external_data)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mas_query_result()\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m QueryResult([response] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [[response]])\n\u001b[0;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query_with_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_connect/driver/httpclient.py:209\u001b[0m, in \u001b[0;36mHttpClient._query_with_context\u001b[0;34m(self, context)\u001b[0m\n\u001b[1;32m    207\u001b[0m     fields \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    208\u001b[0m     headers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext/plain; charset=utf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 209\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mserver_wait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstreaming\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m byte_source \u001b[38;5;241m=\u001b[39m RespBuffCls(ResponseSource(response))  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    217\u001b[0m context\u001b[38;5;241m.\u001b[39mset_response_tz(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_tz_change(response\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX-ClickHouse-Timezone\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_connect/driver/httpclient.py:428\u001b[0m, in \u001b[0;36mHttpClient._raw_request\u001b[0;34m(self, data, params, headers, method, retries, stream, server_wait, fields, error_handler)\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_handler:\n\u001b[1;32m    427\u001b[0m     error_handler(response)\n\u001b[0;32m--> 428\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_error_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/clickhouse_connect/driver/httpclient.py:353\u001b[0m, in \u001b[0;36mHttpClient._error_handler\u001b[0;34m(self, response, retried)\u001b[0m\n\u001b[1;32m    351\u001b[0m     err_msg \u001b[38;5;241m=\u001b[39m common\u001b[38;5;241m.\u001b[39mformat_error(err_content\u001b[38;5;241m.\u001b[39mdecode(errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbackslashreplace\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    352\u001b[0m     err_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_msg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 353\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m OperationalError(err_str) \u001b[38;5;28;01mif\u001b[39;00m retried \u001b[38;5;28;01melse\u001b[39;00m DatabaseError(err_str) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: :HTTPDriver for http://10.80.131.73:8123 returned response code 400)\n Code: 62. DB::Exception: Syntax error: failed at position 1605 ('create') (line 57, col 1): create view cve_data as\n  SELECT DISTINCT\n    v.id as id,\n    v.doc_xml_date as doc_xml_date,\n    v.cve as cve,\n    v.title as vul_title,\n    v.cwe as cwe,\n    . Expected one of: token, Comma, FROM, SELECT. (SYNTAX_ERROR) (version 24.4.1.2088 (official build))\n"
     ]
    }
   ],
   "source": [
    "with open('FillData.sql', 'r') as f:\n",
    "    query = f.read()\n",
    "    f.close()\n",
    "query = query.split(';')\n",
    "for i in query:\n",
    "    connection.query(i)\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
