{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import xml.etree.ElementTree as ET\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "document_info_index = 0\n",
    "document_info_date = ''\n",
    "\n",
    "vulnerability_db = {\"VulnerabilityID\":[],\"DocumentIDFK\":[],\"DockXMLDate\":[], \"Ordinal\":[], \"CVE\":[], \"Title\":[]}\n",
    "vulnerability_db_status = {\"VulnerabilityFK\":[], \"StatusType\": [], \"ProductID\":[]}\n",
    "vulnerability_db_notes = {\"VulnerabilityFK\":[], \"NotesTitle\":[], \"NotesType\":[], \"NotesOrdinal\":[], \"Note\":[]}\n",
    "vulnerability_db_threats = {\"VulnerabilityFK\":[], \"TreatsType\":[], \"Description\":[], \"ProductID\":[]}\n",
    "vulnerability_db_score_set = {\"VulnerabilityFK\":[],\"BaseScore\":[], \"TemporalScore\":[], \"Vector\":[], 'ProductID':[]}\n",
    "vulnerability_db_acknowledgment= {\"VulnerabilityFK\":[], \"Name\":[], \"URL\":[]}\n",
    "vulnerability_db_revision = {\"VulnerabilityFK\":[], \"Number\":[], 'Date':[], 'Description':[]}\n",
    "\n",
    "productdb = {'ProductID':[], 'ProductName':[], 'productdbType':[], 'productdbName':[]}\n",
    "\n",
    "notes_db = {\"DocumentIDFK\":[], \"NoteID\": [], \"notes_dbTitle\":[], \"notes_dbAudience\":[], \"notes_dbType\":[], \"Ordinal\":[]}\n",
    "\n",
    "document_info_db = {\"DocumentID\":[], \"ID\":[], \"Alias\":[], 'Status':[], \"Version\":[], \"RevisionHistoryNumber\":[], \"RevisionHistoryDate\":[], \n",
    "                    \"RevisionHistoryDescription\":[], \"InitialReleaseDate\":[], \"CurrentReleaseDate\":[], 'Pubishertype':[], 'ContactDetails':[], 'IssuingAuthority':[], \n",
    "                    'DocumentTitle':[], 'DocumentType':[], 'vuln':[],'dc':[],'cvrf-common':[],'prod':[],'scap-core':[],'cvssv2':[],'cpe-lang':[],'sch':[],'cvrf':[]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ProductTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_tree(soup, productdb):\n",
    "    library = soup.find('ProductTree')\n",
    "\n",
    "    def process_node(node, productdb):\n",
    "\n",
    "        if node.name is not None:\n",
    "            if 'ProductID' in node.attrs:\n",
    "                productdb['ProductID'].append(node.attrs['ProductID'])\n",
    "                productdb['ProductName'].append(node.text)\n",
    "            \n",
    "            if 'Type' not in node.attrs and node.name != 'ProductTree':\n",
    "                if 'Type' in node.parent.attrs:\n",
    "                    productdb['productdbType'].append(node.parent.attrs['Type'])\n",
    "                    productdb['productdbName'].append(node.parent.attrs['Name'])\n",
    "                else:\n",
    "                    productdb['productdbType'].append(None)\n",
    "                    productdb['productdbName'].append(None)\n",
    "\n",
    "            for child in node.children:\n",
    "                process_node(child, productdb)\n",
    "\n",
    "\n",
    "    process_node(library, productdb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Vulnerability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_Vulnerability(soup, vulnerability_db, vulnerability_db_status, vulnerability_db_notes, vulnerability_db_threats, vulnerability_db_score_set,vulnerability_db_acknowledgment, vulnerability_db_revision):\n",
    "    def process_vulnerability(node, vulnerability_db, vulnerability_index):\n",
    "        vulnerability_db['Ordinal'].append(node.get('Ordinal'))\n",
    "        vulnerability_db['Title'].append(node.find('Title').text if node.find('Title').text else None)\n",
    "        vulnerability_db['CVE'].append(node.find('CVE').text)\n",
    "        vulnerability_db['VulnerabilityID'].append(vulnerability_index+1)\n",
    "        vulnerability_db['DockXMLDate'].append(document_info_date)\n",
    "\n",
    "    def process_status(node, vulnerability_db_status, vulnerability_index):\n",
    "        vulnerability_db_status['ProductID'].append(node.text)\n",
    "        vulnerability_db_status['StatusType'].append(node.parent.get('Type'))\n",
    "        vulnerability_db_status['VulnerabilityFK'].append(vulnerability_index)\n",
    "\n",
    "    def process_notes(node, vulnerability_db_notes, vulnerability_index):\n",
    "        vulnerability_db_notes['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_notes['NotesTitle'].append(node.get('Title'))\n",
    "        vulnerability_db_notes['NotesType'].append(node.get('Type'))\n",
    "        vulnerability_db_notes['NotesOrdinal'].append(node.get('Ordinal'))\n",
    "        vulnerability_db_notes['Note'].append(node.text)\n",
    "\n",
    "    def process_threats(node, vulnerability_db_threats, vulnerability_index):\n",
    "        vulnerability_db_threats['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_threats['TreatsType'].append(node.get('Type'))\n",
    "        product_id = node.find('ProductID')\n",
    "        vulnerability_db_threats['ProductID'].append(product_id.text if product_id else None)\n",
    "        description = node.find('Description')\n",
    "        vulnerability_db_threats['Description'].append(description.text if description else None)\n",
    "\n",
    "    def process_score_set(node, vulnerability_db_score_set, vulnerability_index):\n",
    "        vulnerability_db_score_set['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_score_set['BaseScore'].append(node.find('BaseScore').text)\n",
    "        vulnerability_db_score_set['TemporalScore'].append(node.find('TemporalScore').text)\n",
    "        vulnerability_db_score_set['Vector'].append(node.find('Vector').text)\n",
    "        vulnerability_db_score_set['ProductID'].append(node.find('ProductID').text)\n",
    "\n",
    "    def process_acknowledgment(node, vulnerability_db_acknowledgment, vulnerability_index):\n",
    "        vulnerability_db_acknowledgment['VulnerabilityFK'].append(vulnerability_index)\n",
    "        name = node.find('Name')\n",
    "        vulnerability_db_acknowledgment['Name'].append(name.text if name and name.text else None)\n",
    "        url = node.find('URL')\n",
    "        vulnerability_db_acknowledgment['URL'].append(url.text if url and url.text else None)\n",
    "\n",
    "    def process_revision(node, vulnerability_db_revision, vulnerability_index):\n",
    "        vulnerability_db_revision['VulnerabilityFK'].append(vulnerability_index)\n",
    "        vulnerability_db_revision['Number'].append(node.find('Number').text)\n",
    "        vulnerability_db_revision['Date'].append(node.find('Date').text)\n",
    "        vulnerability_db_revision['Description'].append(node.find('Description').text if node.find('Description').text else None)\n",
    "\n",
    "\n",
    "    def vulnerability(node, vulnerability_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        \n",
    "        vulnerability_index = len(vulnerability_db['Ordinal']) - 1\n",
    "        \n",
    "\n",
    "        if node.name == 'Vulnerability' and 'Ordinal' in node.attrs:\n",
    "            process_vulnerability(node, vulnerability_db, vulnerability_index)\n",
    "        elif node.name == 'ProductID' and node.parent.name == \"Status\":\n",
    "            process_status(node, vulnerability_db_status, vulnerability_index)\n",
    "        elif node.name == 'Note' and node.parent.name == \"Notes\":\n",
    "            process_notes(node, vulnerability_db_notes, vulnerability_index)\n",
    "        elif node.name == 'Threat' and node.parent.name == \"Threats\":\n",
    "            process_threats(node, vulnerability_db_threats, vulnerability_index)\n",
    "        elif node.name == 'ScoreSet' and node.parent.name == \"CVSSScoreSets\":\n",
    "            process_score_set(node, vulnerability_db_score_set, vulnerability_index)\n",
    "        elif node.name == 'Acknowledgment' and node.parent.name == 'Acknowledgments':\n",
    "            process_acknowledgment(node, vulnerability_db_acknowledgment, vulnerability_index)\n",
    "        elif node.name == 'Revision' and node.parent.name == 'RevisionHistory':\n",
    "            process_revision(node, vulnerability_db_revision, vulnerability_index)\n",
    "\n",
    "        for child in node.children:\n",
    "            vulnerability(child, vulnerability_db)\n",
    "\n",
    "\n",
    "    lib = soup.find('cvrfdoc').children\n",
    "    for child in lib:\n",
    "        if child.name == \"Vulnerability\":\n",
    "            vulnerability_db['DocumentIDFK'].append(document_info_index)\n",
    "            vulnerability(child, vulnerability_db)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DocumentNotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_DocumentNotes(soup, notes_db):\n",
    "    def document_notes(node, notes_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        notes_index = len(notes_db['notes_dbAudience'])\n",
    "        if node.name == 'Note' and node.parent.name == 'DocumentNotes':\n",
    "            notes_db[\"DocumentIDFK\"].append(document_info_index)\n",
    "            notes_db[\"notes_dbTitle\"].append(node.get('Title'))\n",
    "            notes_db[\"notes_dbAudience\"].append(node.get('Audience'))\n",
    "            notes_db[\"notes_dbType\"].append(node.get('Type'))\n",
    "            notes_db[\"Ordinal\"].append(node.get('Ordinal'))\n",
    "            notes_db[\"NoteID\"].append(notes_index)\n",
    "        \n",
    "        for child in node.children:\n",
    "            document_notes(child, notes_db) \n",
    "        \n",
    "\n",
    "    lib = soup.find('cvrfdoc').children\n",
    "    for child in lib:\n",
    "        if child.name == \"DocumentNotes\":\n",
    "            document_notes(child, notes_db)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#DocumentTracking + DocumentPublisher + DocumentType + DocumentTitle + attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Doc_Info(soup, document_info_db):\n",
    "    def documen_tracking(node,document_info_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        \n",
    "        if node.name == \"ID\" and node.parent.name == \"Identification\":\n",
    "            document_info_db[\"ID\"].append(node.text if node.text else None)\n",
    "            document_info_db['DocumentID'].append(document_info_index)\n",
    "        elif node.name == \"Alias\" and node.parent.name == \"Identification\":\n",
    "            document_info_db[\"Alias\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Status\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"Status\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Version\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"Version\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Number\" and node.parent.name == \"Revision\":\n",
    "            document_info_db[\"RevisionHistoryNumber\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Date\" and node.parent.name == \"Revision\":\n",
    "            document_info_db[\"RevisionHistoryDate\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"Description\" and node.parent.name == \"Revision\":\n",
    "            document_info_db[\"RevisionHistoryDescription\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"InitialReleaseDate\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"InitialReleaseDate\"].append(node.text if node.text else None)\n",
    "        elif node.name == \"CurrentReleaseDate\" and node.parent.name == \"DocumentTracking\":\n",
    "            document_info_db[\"CurrentReleaseDate\"].append(node.text if node.text else None)\n",
    "    \n",
    "    \n",
    "        for child in node.children:\n",
    "            documen_tracking(child, document_info_db) \n",
    "\n",
    "    def documen_publisher(node,document_info_db):\n",
    "        if node.name is None:\n",
    "            return\n",
    "        \n",
    "        if node.name == 'DocumentPublisher' and node.parent.name == 'cvrfdoc':\n",
    "            document_info_db['Pubishertype'].append(node.get('Type'))\n",
    "        if node.name == 'ContactDetails' and node.parent.name == 'DocumentPublisher':\n",
    "            document_info_db['ContactDetails'].append(node.text if node.text else None)\n",
    "        if node.name == 'IssuingAuthority' and node.parent.name == 'DocumentPublisher':\n",
    "            document_info_db['IssuingAuthority'].append(node.text if node.text else None)\n",
    "\n",
    "        for child in node.children:\n",
    "            documen_publisher(child, document_info_db) \n",
    "\n",
    "    lib = soup.find('cvrfdoc')\n",
    "\n",
    "    document_info_db['vuln'].append(lib.get('xmlns:vuln'))\n",
    "    document_info_db['dc'].append(lib.get('xmlns:dc'))\n",
    "    document_info_db['cvrf-common'].append(lib.get('xmlns:cvrf-common'))\n",
    "    document_info_db['scap-core'].append(lib.get('xmlns:scap-core'))\n",
    "    document_info_db['prod'].append(lib.get('xmlns:prod'))\n",
    "    document_info_db['cvssv2'].append(lib.get('xmlns:cvssv2'))\n",
    "    document_info_db['cpe-lang'].append(lib.get('xmlns:cpe-lang'))\n",
    "    document_info_db['sch'].append(lib.get('xmlns:sch'))\n",
    "    document_info_db['cvrf'].append(lib.get('xmlns:cvrf'))\n",
    "\n",
    "    lib = soup.find('cvrfdoc').children\n",
    "    for child in lib:\n",
    "        if child.name == \"DocumentTracking\":\n",
    "            documen_tracking(child, document_info_db)\n",
    "        if child.name == \"DocumentPublisher\":\n",
    "            documen_publisher(child, document_info_db)\n",
    "        if child.name == 'DocumentTitle':\n",
    "            document_info_db['DocumentTitle'].append(child.text if child.text else None)\n",
    "        if child.name == 'DocumentType':\n",
    "            document_info_db['DocumentType'].append(child.text if child.text else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-Aug\n",
      "['CVE-2023-36787' 'CVE-2023-4427' 'CVE-2023-4428' 'CVE-2023-4431'\n",
      " 'CVE-2023-4430' 'CVE-2023-4429' 'CVE-2023-21709' 'CVE-2023-35368'\n",
      " 'CVE-2023-35359' 'CVE-2023-36865' 'CVE-2023-36866' 'CVE-2023-36873'\n",
      " 'CVE-2023-36876' 'CVE-2023-36882' 'CVE-2023-36889' 'CVE-2023-36898'\n",
      " 'CVE-2023-36899' 'CVE-2023-36900' 'CVE-2023-36903' 'CVE-2023-36904'\n",
      " 'CVE-2023-36905' 'CVE-2023-36906' 'CVE-2023-36907' 'CVE-2023-36908'\n",
      " 'CVE-2023-36909' 'CVE-2023-36910' 'CVE-2023-36911' 'CVE-2023-36912'\n",
      " 'CVE-2023-36913' 'CVE-2023-36914' 'CVE-2023-35376' 'CVE-2023-38254'\n",
      " 'CVE-2023-35377' 'CVE-2023-35378' 'CVE-2023-35379' 'CVE-2023-35380'\n",
      " 'CVE-2023-35381' 'CVE-2023-35382' 'CVE-2023-35383' 'CVE-2023-35384'\n",
      " 'CVE-2023-35385' 'CVE-2023-35386' 'CVE-2023-35387' 'CVE-2023-35389'\n",
      " 'CVE-2023-35393' 'CVE-2023-35394' 'CVE-2023-38188' 'CVE-2023-38186'\n",
      " 'CVE-2023-38185' 'CVE-2023-38184' 'CVE-2023-20569' 'CVE-2023-38175'\n",
      " 'CVE-2023-38172' 'CVE-2023-38170' 'CVE-2023-38169' 'CVE-2023-38167'\n",
      " 'ADV230003' 'CVE-2023-38157' 'CVE-2023-4068' 'CVE-2023-4069'\n",
      " 'CVE-2023-4070' 'CVE-2023-4071' 'CVE-2023-4073' 'CVE-2023-4074'\n",
      " 'CVE-2023-4076' 'CVE-2023-4075' 'CVE-2023-4077' 'CVE-2023-4072'\n",
      " 'CVE-2023-4078' 'CVE-2023-4572' 'CVE-2023-35371' 'CVE-2023-35372'\n",
      " 'CVE-2023-29330' 'CVE-2023-29328' 'CVE-2023-36877' 'CVE-2023-36881'\n",
      " 'CVE-2023-36869' 'CVE-2023-36890' 'CVE-2023-36891' 'CVE-2023-36892'\n",
      " 'CVE-2023-36893' 'CVE-2023-36894' 'CVE-2023-36895' 'CVE-2023-36896'\n",
      " 'CVE-2023-36897' 'CVE-2023-35388' 'CVE-2023-35390' 'CVE-2023-35391'\n",
      " 'CVE-2023-38182' 'CVE-2023-38181' 'CVE-2023-38180' 'CVE-2023-38178'\n",
      " 'CVE-2023-38176' 'CVE-2023-38154' 'ADV230004' 'CVE-2023-36769'\n",
      " 'CVE-2023-2312' 'CVE-2023-4349' 'CVE-2023-4368' 'CVE-2023-4367'\n",
      " 'CVE-2023-4366' 'CVE-2023-4365' 'CVE-2023-4364' 'CVE-2023-4363'\n",
      " 'CVE-2023-4362' 'CVE-2023-4361' 'CVE-2023-4360' 'CVE-2023-4359'\n",
      " 'CVE-2023-4358' 'CVE-2023-4357' 'CVE-2023-4356' 'CVE-2023-4355'\n",
      " 'CVE-2023-4354' 'CVE-2023-4353' 'CVE-2023-4352' 'CVE-2023-4351'\n",
      " 'CVE-2023-4350' 'CVE-2023-36741' 'CVE-2023-38158' 'CVE-2023-3611'\n",
      " 'CVE-2023-4004' 'CVE-2023-3812' 'CVE-2023-36054' 'CVE-2023-4194'\n",
      " 'CVE-2023-4128' 'CVE-2021-32292' 'CVE-2023-35945' 'CVE-2023-38403'\n",
      " 'CVE-2023-38409' 'CVE-2023-3610' 'CVE-2018-11694' 'CVE-2023-3776'\n",
      " 'CVE-2023-3609' 'CVE-2023-3863' 'CVE-2023-37369' 'CVE-2023-32248'\n",
      " 'CVE-2023-3567' 'CVE-2023-38697' 'CVE-2023-4132' 'CVE-2023-2860'\n",
      " 'CVE-2023-4147' 'CVE-2023-3896' 'CVE-2023-40225' 'CVE-2023-39417'\n",
      " 'CVE-2023-33951' 'CVE-2023-33952']\n"
     ]
    }
   ],
   "source": [
    "# doc_month_array = [\"Aug\",\"Sep\",'Oct', \"Nov\", \"Dec\", \"Jan\", 'Feb', \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\"]\n",
    "# doc_year_array = ['2023', '2024']\n",
    "\n",
    "for i in ['2023']:\n",
    "    for j in [\"Aug\"]:\n",
    "        soup = \"\"\n",
    "        url = f'https://api.msrc.microsoft.com/cvrf/v3.0/cvrf/{i}-{j}'\n",
    "\n",
    "        # Получаем данные по ссылке\n",
    "        response = requests.get(url)\n",
    "\n",
    "        # Проверка успешности запроса\n",
    "        if response.status_code == 200:\n",
    "            print(f\"{i}-{j}\")\n",
    "            document_info_date = f\"{i}-{j}\"\n",
    "            document_info_index +=1\n",
    "            soup = BeautifulSoup(response.content, \"xml\")\n",
    "            product_tree(soup, productdb)\n",
    "            Get_Vulnerability(soup, vulnerability_db, vulnerability_db_status, vulnerability_db_notes, vulnerability_db_threats, vulnerability_db_score_set,vulnerability_db_acknowledgment, vulnerability_db_revision)\n",
    "            Get_DocumentNotes(soup, notes_db)\n",
    "            Doc_Info(soup, document_info_db)\n",
    "\n",
    "\n",
    "            \n",
    "        else:\n",
    "            print(\"Не удалось получить данные, статус код:\", response.status_code)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "productdb = pd.DataFrame(productdb)\n",
    "vulnerability_db = pd.DataFrame(vulnerability_db)\n",
    "vulnerability_db_status = pd.DataFrame(vulnerability_db_status)\n",
    "vulnerability_db_notes = pd.DataFrame(vulnerability_db_notes)\n",
    "vulnerability_db_threats = pd.DataFrame(vulnerability_db_threats)\n",
    "vulnerability_db_score_set = pd.DataFrame(vulnerability_db_score_set)\n",
    "vulnerability_db_acknowledgment = pd.DataFrame(vulnerability_db_acknowledgment)\n",
    "vulnerability_db_revision = pd.DataFrame(vulnerability_db_revision)\n",
    "notes_db = pd.DataFrame(notes_db)\n",
    "document_info_db = pd.DataFrame(document_info_db)\n",
    "\n",
    "cve_table = vulnerability_db['CVE'].unique()\n",
    "print(cve_table)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# vulnerability_db = vulnerability_db.head(20)\n",
    "\n",
    "# vulnerability_db_status = pd.merge(vulnerability_db, vulnerability_db_status, left_on = \"VulnerabilityID\", right_on='VulnerabilityFK', how='inner')\n",
    "# vulnerability_db_score_set = pd.merge(vulnerability_db, vulnerability_db_score_set, left_on = \"VulnerabilityID\", right_on='VulnerabilityFK', how='inner')\n",
    "# vulnerability_db_acknowledgment= pd.merge(vulnerability_db, vulnerability_db_acknowledgment, left_on = \"VulnerabilityID\", right_on='VulnerabilityFK', how='inner')\n",
    "# vulnerability_db_notes= pd.merge(vulnerability_db, vulnerability_db_notes, left_on = \"VulnerabilityID\", right_on='VulnerabilityFK', how='inner')\n",
    "# vulnerability_db_threats= pd.merge(vulnerability_db, vulnerability_db_threats, left_on = \"VulnerabilityID\", right_on='VulnerabilityFK', how='inner')\n",
    "# vulnerability_db_revision= pd.merge(vulnerability_db, vulnerability_db_revision, left_on = \"VulnerabilityID\", right_on='VulnerabilityFK', how='inner')\n",
    "\n",
    "\n",
    "# vulnerability_db_status.drop(columns=['VulnerabilityFK', 'Ordinal'], inplace=True)\n",
    "# vulnerability_db_score_set.drop(columns=['VulnerabilityFK', 'DocumentIDFK', 'Ordinal', 'CVE', 'Title', 'ProductID'], inplace=True)\n",
    "# vulnerability_db_acknowledgment.drop(columns=['VulnerabilityFK', 'DocumentIDFK', 'Ordinal', 'CVE', 'Title'], inplace=True)\n",
    "# vulnerability_db_notes.drop(columns=['VulnerabilityFK', 'DocumentIDFK', 'CVE', 'Title', 'Ordinal'], inplace=True)\n",
    "# vulnerability_db_threats.drop(columns=['VulnerabilityFK', 'DocumentIDFK', 'Ordinal', 'CVE', 'Title', 'ProductID'], inplace=True)\n",
    "# vulnerability_db_revision.drop(columns=['VulnerabilityFK', 'DocumentIDFK', 'Ordinal', 'CVE', 'Title'],  inplace=True)\n",
    "\n",
    "# notes_db.drop(columns='Ordinal', inplace=True)\n",
    "\n",
    "# # print(vulnerability_db_score_set)\n",
    "\n",
    "# result = pd.merge(vulnerability_db_status, vulnerability_db_score_set, on= 'VulnerabilityID', how='inner')\n",
    "\n",
    "# grop_prod = result.groupby('CVE')['ProductID'].agg(lambda x: list(set(x))).reset_index()\n",
    "\n",
    "# group_var =  result.groupby('CVE')['Title'].agg(lambda x: list(set(x))[0]).reset_index()\n",
    "# grop_prod = pd.merge(grop_prod, group_var, on = 'CVE', how = 'inner')\n",
    "\n",
    "# group_var =  result.groupby('CVE')['StatusType'].agg(lambda x: list(set(x))[0]).reset_index()\n",
    "# grop_prod = pd.merge(grop_prod, group_var, on = 'CVE', how = 'inner')\n",
    "\n",
    "# group_var =  result.groupby('CVE')['BaseScore'].agg(lambda x: list(set(x))[0]).reset_index()\n",
    "# grop_prod = pd.merge(grop_prod, group_var, on = 'CVE', how = 'inner')\n",
    "\n",
    "# group_var =  result.groupby('CVE')['TemporalScore'].agg(lambda x: list(set(x))[0]).reset_index()\n",
    "# grop_prod = pd.merge(grop_prod, group_var, on = 'CVE', how = 'inner')\n",
    "\n",
    "# group_var =  result.groupby('CVE')['Vector'].agg(lambda x: list(set(x))[0]).reset_index()\n",
    "# grop_prod = pd.merge(grop_prod, group_var, on = 'CVE', how = 'inner')\n",
    "\n",
    "# group_var =  result.groupby('CVE')['VulnerabilityID'].agg(lambda x: list(set(x))).reset_index()\n",
    "# grop_prod = pd.merge(grop_prod, group_var, on = 'CVE', how = 'inner')\n",
    "# # result = pd.merge(result, vulnerability_db_threats, on= 'VulnerabilityID', how='inner')\n",
    "# # # result = result.head(256)\n",
    "# # result = pd.merge(result, vulnerability_db_notes, on = 'VulnerabilityID', how='inner')\n",
    "# # result = pd.merge(result, vulnerability_db_acknowledgment, on = 'VulnerabilityID', how='inner')\n",
    "# # result = pd.merge(result, vulnerability_db_revision, on= 'VulnerabilityID', how ='inner')\n",
    "\n",
    "# # result = pd.merge(result, productdb, on='ProductID', how='inner')\n",
    "\n",
    "# # result = pd.merge(result, notes_db, on = 'DocumentIDFK', how='inner')\n",
    "\n",
    "# # result = pd.merge(result, document_info_db, left_on='DocumentIDFK', right_on= 'DocumentID', how='inner')\n",
    "\n",
    "\n",
    "# print(grop_prod)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Match KB & CVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Release date    Article      Build Number             CVE  \\\n",
      "0     2023-08-08  KB4484489    15.0.5579.1001       ADV230003   \n",
      "1     2023-08-08  KB4504720    16.0.5408.1001       ADV230003   \n",
      "2     2023-08-08  KB5002328    16.0.5408.1001       ADV230003   \n",
      "3     2023-08-08  KB5002391    15.0.5579.1001       ADV230003   \n",
      "4     2023-08-08  KB5002399    15.0.5579.1001       ADV230003   \n",
      "..           ...        ...               ...             ...   \n",
      "629   2024-09-10  KB5002639  16.0.10414.20002  CVE-2024-43466   \n",
      "630   2024-09-10  KB5002640  16.0.17928.20086  CVE-2024-43466   \n",
      "631   2024-09-10  KB5043254            9.1.32  CVE-2024-43476   \n",
      "632   2024-09-10  KB5040438   10.0.25398.1009  CVE-2024-43495   \n",
      "633   2024-09-10  KB5040442   10.0.22621.3880  CVE-2024-43495   \n",
      "\n",
      "     VulnerabilityID DockXMLDate  \n",
      "0               56.0    2023-Aug  \n",
      "1               56.0    2023-Aug  \n",
      "2               56.0    2023-Aug  \n",
      "3               56.0    2023-Aug  \n",
      "4               56.0    2023-Aug  \n",
      "..               ...         ...  \n",
      "629              NaN         NaN  \n",
      "630              NaN         NaN  \n",
      "631              NaN         NaN  \n",
      "632              NaN         NaN  \n",
      "633              NaN         NaN  \n",
      "\n",
      "[634 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "kb_lake = pd.read_csv('Security Updates 2024-10-08-021008pm.csv')\n",
    "\n",
    "kb_lake['Release date'] = pd.to_datetime(kb_lake['Release date'])\n",
    "kb_lake = kb_lake.loc[kb_lake.groupby('Article')['Release date'].idxmax()].reset_index()\n",
    "kb_lake = kb_lake[kb_lake['Article'].apply(lambda x: isinstance(x, int)) | kb_lake['Article'].astype(str).str.isnumeric()]\n",
    "kb_lake.drop(columns=['Product', 'Platform', 'Article (Link)', 'Download', 'Download (Link)', 'Impact', 'Max Severity', 'Details (Link)', 'index'],  inplace=True)\n",
    "kb_lake['Article'] = 'KB'+ kb_lake['Article']\n",
    "kb_lake.rename(columns={\"Details\": 'CVE'}, inplace=True)\n",
    "kb_lake = pd.merge(kb_lake, vulnerability_db, on='CVE', how='outer')\n",
    "kb_lake.drop(columns=['Ordinal', 'Title', 'DocumentIDFK'], inplace=True)\n",
    "\n",
    "kb_lake.to_excel(\"result.xlsx\")\n",
    "print(kb_lake)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
